# -*- coding: utf-8 -*-
"""trabajo_tec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17plAoZZIQoI9vHc7v-h5gdZjjk9KhG7O
"""

pip install datasets

from datasets import load_dataset
import PIL
import pandas as pd
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from IPython.display import display
from tqdm import tqdm
import pickle

#para importar datasets que tiene la libreria
import torchvision

dataset = load_dataset("cifar10") #cargamos el dataset

train_df = dataset["train"] #separamos en train
test_df = dataset["test"] #separamos en test

#funciones especial de tensor en la que se pueden aplicar transformadas directamente a imágenes para que puedan ser leídas por la librería:
to_tensor = transforms.ToTensor() #pasamos de df a tensor mediante la función

#esta función en concreto, transforma el tipo de imagen a ua PILImage, lo  que da a python capacidad de lectura y edición de las fotos
to_pil = transforms.ToPILImage()  #transformamos las imágenes

#no es extrictamemte necesario
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #almacenamiento de la información a la CPU (creo que solo se puede ejcutar en windows)

class TrainDataset(Dataset):  #clase para tratar los datos de entrenamiento
  def __len__(self):  #atribtuto privado para saber la longitud de los datos de entrenamiento
    return len(train_df)

  def __getitem__(self, index): #devuelve el elemnto en una posición específica de una lista
    img_x = train_df[index]["img"].resize((32, 32)) #coge la imagen de una posición específica de la lista y reescala la imagen a 32x32
    return (to_tensor(img_x), torch.tensor([train_df[index]["label"]])) #cambiamos el formato de la imagena a tensory generamos un constructor de tensor con la imagen de los datos de entrenamiento
                                                      #la función label retorna el tipo de elemento y la fila o columna sobre la que se está trabajando



class TestDataset(Dataset): #clase de estudio de los datos para comprobar el entrenamiento
  def __len__(self):  #longitud de los datos test
    return len(test_df)


#retorna una tupla
  def __getitem__(self, index):
    img_x = test_df[index]["img"].resize((32, 32))  #coge la imagen de una posición específica de la lista y la reescala a un fromato 32x32
    return (to_tensor(img_x), torch.tensor([test_df[index]["label"]]))#cambiamos el formato de la imagen a tensor y generamos un constructor de tensor con la imagen de los datos de entrenemiento

train_dataset = TrainDataset() #se llama a la función con los datos de etrenamiento
test_dataset = TestDataset()  #se llama a la función con los datos de testeo


train_set = DataLoader( #sobre los datos de entrenamiento, se aplica el DataLoader, es una preparación de los datos 
    train_dataset,
    batch_size = 200, #cuantas muestras procesar en cada proceso
    shuffle = True  #datos mezclados en cada epoch, muy útil para el entrenamiento de los datos
)

test_set = DataLoader(  #aplicamos lo mismo pero sin atributos sobre los datos de test
    test_dataset
)

#se genera un dataframe con los datos de entrenamiento, y los de test(antes estaban en torch)
df_test = pd.DataFrame(test_set)
df_train = pd.DataFrame(train_set)

#se pasa la información a un csv
df_test.to_csv("test.csv", index = False)

#función train a la que se pasa por parámetro el valor real y la estimación
def train(input, real):
      #muy importante que el gradiente se ponga a cero en cada iteración porque si no, los datos se van almacenando en la misma
      #parte de memoria y al final, tendremos la suma de todos los gradientes
  optim.zero_grad()

  #input es lo que nos saca el modelo
  output = model(input)
  # la pérdida es la desviacón típica al cuadrado
  lost = loss_function(output, real)

  #se aplica el algoritmo hacia atrás para cualcular el gradiente
  lost.backward()
  optim.step()

  return lost

def encode_labels(batch_size, input):
  data = torch.zeros((batch_size, 10)).to(device)
  for i, j in enumerate(input):
    data[i][j.item()] = 1
  return data

#en nuestro df solo hay dos columnas, una con las imágenes y otra con su clasificación
df_train.columns = ["img", "label"]
df_test.columns = ["img", "label"]

#clase del modelo (no sé lo que hace pero el nuestro será diferente aunque parecido por la comparación de imágenes)
class Model(nn.Module):

  #constructor del model
  def __init__(self):

    super().__init__()

    #Aquí los que se está haciendo es preparar la imagen para leugo poderla pasar al modelo de clasificación de imágenes

    #creo que estas son las capas de la red neuronal
    self.features = nn.Sequential(
      #Conv2d método para generar un red convolucional            CNN video YT
      #se pasan por parámetro las dimensiones 3x64
      nn.Conv2d(3, 64, 3, 1, 1),
      #siempre se pasa por parámetro la segunda diemnsión de la capa
      nn.BatchNorm2d(64),

      #FUNCIÓN DE ACTIVACIÓN (más abajo lo explico)
      nn.ReLU(),

      nn.Dropout(p=0.3),

      #la siguiente capa debe empezar por el mismo número que terminó la anyterior (64)
      nn.Conv2d(64, 128, 3, 1, 1),
      nn.BatchNorm2d(128),
      #relacion que existe entre las capas neuronales que hemos definido
      nn.ReLU(),
      #tipo de capa ue se usa en redes neuronales para aplicar un pool máximo de 2d sobre una señal input formada de muchos planos input  (una foto)
      #fracciona un conjunto de datos y los divide en varios cuadrantes y coge el valor valor de cada uno de ellos, generando otro conjunto de datos y así de forma sucesiva
      #reduce el coste computacional de la lectura de las imágenes porque reduce el tamaño de las mismas. Además eviat el overfitting del modelo 
      nn.MaxPool2d(2, 2),

      nn.Conv2d(128, 256, 3, 1, 1),
      nn.BatchNorm2d(256),
      nn.ReLU(),

      nn.Dropout(p = 0.4),

      nn.Conv2d(256, 512, 3, 1, 1),
      nn.BatchNorm2d(512),
      nn.ReLU(),

      nn.MaxPool2d(2, 2),

      #cada vez que se ejecuta esta sentencia se reduce el tamaño de la imagen
      nn.Conv2d(512, 512, 3, 1, 1),
      nn.BatchNorm2d(512),
      nn.ReLU(),

      nn.Dropout(p = 0.4),

      nn.Conv2d(512, 512, 3, 1, 1),
      nn.BatchNorm2d(512),
      nn.ReLU(),

      nn.MaxPool2d(4, 4)
    )


    #aquí tenemos la lectura de las capas con la función de activación

    #esta función trata a las capas de la neurona como ni fuesen un conjunto o una cadena. Se leen con el mismo orden que entraron. Se dice que se leen en cascada
    self.output = nn.Sequential(
      #aplica una transformación lineal (ax+b) a los datos que se pasan. Los parámetos son los datos de entrada y se salida
      nn.Linear(2048, 512),
      #aplica batch normalization a un conjunto de datos 2d ó 3d
      nn.BatchNorm1d(512),

      #FUNCIÓN DE ACTIVACIÓN
      #Applies the rectified linear unit function element-wi
      #para que los procesos neuronales no sean solo lineales y puedan desarrollar tereas más complejas. Toma valor nulo para valores negativos y luego crece
      #linealmente generando una regresiçon lineal.
      #se usa para las capas ocultas de las neuronas

      #problemas de esta fucnión: al tomar valores nulos, los gradientes también serán nulos y puede que de problemas en el cálculo de los mismos.
      #si pasa, usar LeakyReLu
      nn.ReLU(),

      #proceso de regularización
      nn.Dropout(p = 0.3),

      nn.Linear(512, 10),
    )

  #Una vez hemos definido nuestra red neuronal con todos los elementos y función de activación, llamamos a todos los métodos para que la red pueda implementarse

  #una vez tenemos las imágenes preparadas, las pasamos a clasificación 
  def forward(self, x):
    #los mismos datos (misma variable x) va psando por todos los procesos
    #se aplican  los métodos de arriba a las capas de las neuroas
    #se crea y deifnen las capas de la red neuronal

    #se aplican todos los procesos de convolución de las capas neuronales llamando al método del constructor, para no tener que ir una a una con todas las capas
    x = self.features(x)
    #formato para la distribución correcta de los datos. Se 'aplanan'
    #importante que se pase por parámetro la cantidad de muestras y el valor que conforma la regresión lineal del modelo
    x = x.view(x.size(0), 2048)
    #aplicamos la lectura de las capas
    x = self.output(x)
    return x

#se guarda el modelo en nuetro dispositivo(GPU)
model = Model().to(device)

#método de la librería nnpara calcular la función de error de forma automática
#CrossEntropyLoss esta función mide la actuación de nuestro modelo, teniendo valores de 0 a 1 usudao en probabilidad de multiclases
# a mayor sea este parámetro, peor aproximará nuestro modelo
#dentro de esta función, ya se está implementando otra my importante de esta libreria (softmax) es importante que si ya estamos usando CossEntropyLoss, no la usemos para el mismo modelo 
loss_function = nn.CrossEntropyLoss()
optim = torch.optim.SGD(model.parameters(), lr = 0.01)

#función repetida
def train(input, real):
  optim.zero_grad()

  output = model(input)
  lost = loss_function(output, real)

  lost.backward()

  #FUCNIÓN DE ACTIVACIÓN
  #realiza un único paso de optimización
  #parámetro de actualización
  optim.step()

  return lost

#creo que repetida también
def encode_labels(batch_size, input):
  data = torch.zeros((batch_size, 10)).to(device)
  for i, j in enumerate(input):
    data[i][j.item()] = 1
  return data

#carga de todos los errores
history_loss = []
#iteraciones que se realizan
epochs = 300
#ejecución del entrenamiento
#en este punto vemos como el error va decreciendo y se va entrenando el modelo con todas las fotos de categorias diferentes 
for epoch in range(epochs):
  epoch_loss = 0
  for i in tqdm(range(len(df_train)), position=0, leave=True):
    input = df_train.iloc[i]["img"].to(device)
    real = encode_labels(200, df_train.iloc[i]["label"])
    epoch_loss = epoch_loss + train(input, real)
  print(f"Epoch:{epoch}. Loss:{epoch_loss.item()/i}")
  history_loss.append(epoch_loss.item()/i)

#guardar el modelo
torch.save(model, "tecnicas_optim.plt")

#gráfico del conjunto de errores
plt.plot(history_loss)

#label: 0-9 with the following correspondence 0 airplane 1 automobile 2 bird 3 cat 4 deer 5 dog 6 frog 7 horse 8 ship 9 truck

model = torch.load("tecnicas_optim.plt")
labeled = {0: "airplane", 1: "automobile", 2: "bird", 3: "cat", 4: "deer", 5: "dog", 6: "frog", 7: "horse", 8: "ship", 9: "truck"}
data = {i: [0, 0] for i in labeled.keys()}
model.eval()
#esto no es necesario hacerlo
with torch.no_grad():
  for i in range(len(df_test)):
    input = df_test.iloc[i]["img"].to(device)
    real = df_test.iloc[i]["label"]
    out = model(input)
    data[real.item()][1] += 1
    if torch.argmax(out[0]).item() == real.item():
      data[real.item()][0] += 1

print(data)

pip freeze > requirements.txt



